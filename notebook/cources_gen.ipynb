{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "468c77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Any\n",
    "from IPython.display import Image, display\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a91c8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Models for Quiz Variants ---\n",
    "class FlashCardData(BaseModel):\n",
    "    word_hanzi: str\n",
    "    pinyin: str\n",
    "    definition_en: str\n",
    "    definition_vi: str\n",
    "    example_sentence: Optional[str] = None\n",
    "    example_pinyin: Optional[str] = None\n",
    "    example_meaning_en: Optional[str] = None\n",
    "    example_meaning_vi: Optional[str] = None\n",
    "    extra_info_md: Optional[str] = None\n",
    "\n",
    "class QuizOptionData(BaseModel):\n",
    "    \"\"\"Used for Single Choice, Multiple Choice, Listening, Image Selection\"\"\"\n",
    "    text: str = Field(..., description=\"The answer text or label\")\n",
    "    is_correct: bool\n",
    "    order: int\n",
    "    image_url: Optional[str] = Field(None, description=\"URL if the option is an image\")\n",
    "\n",
    "class MatchPairData(BaseModel):\n",
    "    \"\"\"Used for Match Pairs\"\"\"\n",
    "    left_text: str\n",
    "    right_text: str\n",
    "    order: int\n",
    "\n",
    "class SentenceQuizData(BaseModel):\n",
    "    \"\"\"Used for Fill in the Blank, Order Sentence\"\"\"\n",
    "    chinese_sentence: str\n",
    "    pinyin_sentence: Optional[str] = None\n",
    "    correct_answer: Optional[str] = Field(None, description=\"The specific word for 'Fill in the Blank'\")\n",
    "    distractors: List[str] = Field(default_factory=list, description=\"Wrong word blocks\")\n",
    "\n",
    "class TextResponseQuizData(BaseModel):\n",
    "    \"\"\"Used for Translate (CN<->EN/VI) and Writing\"\"\"\n",
    "    source_text: Optional[str] = Field(None, description=\"Text to translate or prompt for writing\")\n",
    "    accepted_answers: List[str] = Field(default_factory=list, description=\"Valid variations of the translation\")\n",
    "    is_strict: bool = False\n",
    "\n",
    "class SpeakingQuizData(BaseModel):\n",
    "    \"\"\"Used for Speaking\"\"\"\n",
    "    expected_text: str\n",
    "    expected_pinyin: Optional[str] = None\n",
    "    time_limit: int = 15\n",
    "\n",
    "# --- Core Models ---\n",
    "\n",
    "class GeneratedQuiz(BaseModel):\n",
    "    quiz_type: Literal[\n",
    "        'Flashcard', \n",
    "        'Single Choice', 'Multiple Choice', 'Image Selection', \n",
    "        'Fill in the Blank', 'Translate to CN', 'Translate from CN', 'Writing',\n",
    "        'Listening', 'Speaking', \n",
    "        'Match Pairs', 'Order Sentence'\n",
    "    ]\n",
    "    \n",
    "    question_en: str\n",
    "    question_vi: str\n",
    "    explanation_en: Optional[str] = None\n",
    "    explanation_vi: Optional[str] = None\n",
    "    \n",
    "    # Media prompts at the Quiz level\n",
    "    audio_url: Optional[str] = None\n",
    "    image_url: Optional[str] = None\n",
    "    \n",
    "    order: int\n",
    "    \n",
    "    # Polymorphic fields: Map the Enum type to the correct data container\n",
    "    # 1. Flashcard\n",
    "    flashcard: Optional[FlashCardData] = None\n",
    "    \n",
    "    # 2. Options (Single Choice, Multiple Choice, Image Selection, Listening)\n",
    "    options: Optional[List[QuizOptionData]] = None\n",
    "    \n",
    "    # 3. Pairs (Match Pairs)\n",
    "    pairs: Optional[List[MatchPairData]] = None\n",
    "    \n",
    "    # 4. Sentence (Fill in the Blank, Order Sentence)\n",
    "    sentence: Optional[SentenceQuizData] = None\n",
    "    \n",
    "    # 5. Text Input (Translate..., Writing)\n",
    "    text_response: Optional[TextResponseQuizData] = None\n",
    "    \n",
    "    # 6. Speaking (Speaking)\n",
    "    speaking: Optional[SpeakingQuizData] = None\n",
    "\n",
    "class GeneratedSection(BaseModel):\n",
    "    # STRICTLY MATCHING YOUR LESSON SECTION TYPE ENUM\n",
    "    section_type: Literal[\n",
    "        'Vocabulary', 'Grammar', 'Reading', 'Listening', \n",
    "        'Speaking', 'Conversation', 'Final Test'\n",
    "    ]\n",
    "    title_en: str\n",
    "    title_vi: str\n",
    "    content_md: Optional[str] = Field(None, description=\"Markdown theory/dialogue text\")\n",
    "    order: int\n",
    "    quizzes: List[GeneratedQuiz] = Field(..., description=\"List of quizzes in this section\")\n",
    "\n",
    "class GeneratedLessonContent(BaseModel):\n",
    "    sections: List[GeneratedSection]\n",
    "    \n",
    "class CritiqueEvaluation(BaseModel):\n",
    "    approved: bool = Field(description=\"Set to True if the content is perfect for the HSK level. False if changes are needed.\")\n",
    "    feedback: str = Field(description=\"Specific instructions on what to fix (e.g., 'The word 'Economy' is too hard for HSK1', 'Distractors in Q3 are too obvious').\")\n",
    "    \n",
    "class SectionBlueprint(BaseModel):\n",
    "    \"\"\"The Architect's plan for a single section.\"\"\"\n",
    "    section_type: Literal['Vocabulary', 'Grammar', 'Reading', 'Listening', 'Speaking', 'Conversation', 'Final Test']\n",
    "    title_en: str\n",
    "    title_vi: str\n",
    "    teaching_goal: str = Field(..., description=\"Pedagogical goal (e.g., 'Introduce basic greetings').\")\n",
    "    required_concepts: List[str] = Field(..., description=\"Specific words or grammar points to cover in this section.\")\n",
    "    recommended_quiz_types: List[str] = Field(..., description=\"Which quiz types best fit this section (e.g., 'Flashcard', 'Match Pairs').\")\n",
    "\n",
    "class LessonBlueprint(BaseModel):\n",
    "    \"\"\"Output of Agent 1\"\"\"\n",
    "    rationale: str = Field(..., description=\"Reasoning for this lesson's structure.\")\n",
    "    sections: List[SectionBlueprint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5be89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-5-mini\", streaming=True,temperature=0.7, api_key=\"\") # GPT-4o is recommended for complex JSON\n",
    "\n",
    "# --- Setup LLMs ---\n",
    "# Planner needs to be smart (GPT-4)\n",
    "planner_llm = llm\n",
    "# Writer needs to be creative but structured (GPT-4)\n",
    "writer_llm = llm\n",
    "# Reviewer needs to be strict (GPT-4)\n",
    "critic_llm = llm\n",
    "\n",
    "\n",
    "# --- Define State ---\n",
    "class AgentState(TypedDict):\n",
    "    # Inputs\n",
    "    course_info: dict\n",
    "    lesson_info: dict\n",
    "    \n",
    "    # Internal State\n",
    "    lesson_plan: Optional[LessonBlueprint]       # Output of Agent 1\n",
    "    draft_content: Optional[GeneratedLessonContent] # Output of Agent 2\n",
    "    \n",
    "    # Feedback Loop\n",
    "    critique_feedback: Optional[str]             # Output of Agent 3\n",
    "    revision_count: int \n",
    "    is_approved: bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a99c457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. AGENT 1: The Architect (Planner) ---\n",
    "def architect_node(state: AgentState):\n",
    "    course = state['course_info']\n",
    "    lesson = state['lesson_info']\n",
    "    \n",
    "    parser = PydanticOutputParser(pydantic_object=LessonBlueprint)\n",
    "    \n",
    "    # FIX: Explicitly list allowed types and FORBID \"Practice\"\n",
    "    system_msg = \"\"\"\n",
    "    You are a Senior HSK Curriculum Architect. \n",
    "    Your job is to PLAN the structure of a lesson. Do not write the quizzes yet.\n",
    "    \n",
    "    ### STRICT ENUM RULES\n",
    "    You must ONLY use the following `section_type` values:\n",
    "    - 'Vocabulary' (For Flashcards)\n",
    "    - 'Grammar' (For Theory)\n",
    "    - 'Reading' (For Text comprehension practice)\n",
    "    - 'Listening' (For Audio comprehension practice)\n",
    "    - 'Speaking' (For Pronunciation)\n",
    "    - 'Conversation' (For Dialogue)\n",
    "    - 'Final Test' (For General Review/Mixed Practice)\n",
    "    \n",
    "    **CRITICAL:** Do NOT use \"Practice\" as a section type. If you want a practice section, use 'Reading', 'Listening', or 'Final Test'.\n",
    "\n",
    "    ### INSTRUCTIONS\n",
    "    1. Analyze the Learning Objectives.\n",
    "    2. Must define 7-8 Sections (Scaffolding: Acquisition -> Application -> Production).\n",
    "    3. Explain WHY each section is needed in the `rationale`.\n",
    "    4. List specific concepts (words/grammar) required for each section.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_msg = \"\"\"\n",
    "    Course: {course_name} ({hsk_level})\n",
    "    Lesson: {lesson_title}\n",
    "    Objectives: {objectives}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_msg),\n",
    "        (\"user\", user_msg),\n",
    "        (\"user\", \"\\nOutput Blueprint JSON:\\n{format_instructions}\")\n",
    "    ])\n",
    "    \n",
    "    formatted_inputs = {\n",
    "        \"course_name\": course['name'],\n",
    "        \"hsk_level\": course['hsk_level'],\n",
    "        \"lesson_title\": lesson['title'],\n",
    "        \"objectives\": lesson['learning_objectives'],\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    }\n",
    "    \n",
    "    # Add error handling to retry if it fails (optional but recommended)\n",
    "    try:\n",
    "        response = planner_llm.invoke(prompt.invoke(formatted_inputs))\n",
    "        return {\"lesson_plan\": parser.parse(response.content)}\n",
    "    except Exception as e:\n",
    "        # If the Architect fails, we can't proceed. In a production app, you might loop here.\n",
    "        # For now, we return empty which will stop the graph gracefully or throw.\n",
    "        print(f\"Architect Error: {e}\") \n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c371b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- AGENT 2: The Content Creator (Writer) ---\n",
    "def writer_node(state: AgentState):\n",
    "    # Inputs\n",
    "    plan = state['lesson_plan']\n",
    "    feedback = state.get('critique_feedback')\n",
    "    revisions = state.get('revision_count', 0)\n",
    "    \n",
    "    parser = PydanticOutputParser(pydantic_object=GeneratedLessonContent)\n",
    "    \n",
    "    system_msg = \"\"\"\n",
    "    You are an Expert Content Writer for a Chinese Learning App (HSK Standard).\n",
    "    Your goal is to turn a high-level Lesson Blueprint into concrete JSON data.\n",
    "\n",
    "    ### GENERAL GUIDELINES\n",
    "    1. **Strict Adherence:** Must follow the `lesson_plan` exactly. If the plan asks for \"Order Sentence\" for \"ä½ å¥½\", do not create a \"Flashcard\".\n",
    "    2. **Language Level:** Use *only* vocabulary appropriate for the target HSK level.\n",
    "    3. **Bilingual:** All explanations/definitions must be in both English (`_en`) and Vietnamese (`_vi`).\n",
    "    4. **Quantity:** Must have at least 18-20 quizzes for a section.\n",
    "\n",
    "    ### QUIZ TYPE SPECIFICATIONS (STRICT RULES)\n",
    "\n",
    "    **1. 'Flashcard' (Vocabulary Only)**\n",
    "       - **Usage:** Introducing new words.\n",
    "       - **Data:** Fill `flashcard` field.\n",
    "       - **Requirements:** - `word_hanzi`: The character(s).\n",
    "         - `pinyin`: The pronunciation in Pinyin.\n",
    "         - `definition_en`: Concise English meaning.\n",
    "         - `definition_vi`: Concise Vietnamese meaning.\n",
    "         - `example_sentence`: A simple sentence (mostly known words + this new word).\n",
    "         - `example_pinyin`: Pinyin for the example sentence.\n",
    "         - `example_meaning_en`: English meaning of the example sentence.\n",
    "         - `example_meaning_vi`: Vietnamese meaning of the example sentence.\n",
    "         - `extra_info_md`: Optional extra info in Markdown (e.g., cultural notes).\n",
    "\n",
    "    **2. 'Single Choice' (Grammar/Reading)**\n",
    "       - **Usage:** Standard testing.\n",
    "       - **Data:** Fill `options` list.\n",
    "       - **Structure:** Exactly **4 Options**.\n",
    "       - **Logic:** 1 Option has `is_correct=True`, 3 Options have `is_correct=False`.\n",
    "       - **Distractors:** Wrong answers must be grammatically plausible or visual lookalikes.\n",
    "\n",
    "    **3. 'Multiple Choice' (Select All)**\n",
    "       - **Usage:** When multiple answers are valid.\n",
    "       - **Data:** Fill `options` list.\n",
    "       - **Logic:** At least 2 Options must be `is_correct=True`.\n",
    "\n",
    "    **4. 'Match Pairs' (Gamification)**\n",
    "       - **Usage:** Testing Vocabulary recall.\n",
    "       - **Data:** Fill `pairs` list.\n",
    "       - **Structure:** Generate exactly at least **4 pairs** per quiz.\n",
    "       - **Format:** `left_text` = Hanzi, `right_text` = Pinyin/Meaning.\n",
    "\n",
    "    **5. 'Order Sentence' (Syntax Practice)**\n",
    "       - **Usage:** Grammar practice.\n",
    "       - **Data:** Fill `sentence` field.\n",
    "       - **Logic:** Provide the **Full Correct Sentence** in `chinese_sentence`.\n",
    "       - **Note:** The Frontend will handle the shuffling. You just provide the correct answer.\n",
    "\n",
    "    **6. 'Fill in the Blank' (Context Practice)**\n",
    "       - **Usage:** Testing specific vocabulary in context.\n",
    "       - **Data:** Fill `sentence` field.\n",
    "       - **Logic:** - `chinese_sentence`: The full sentence *including* the word to be removed.\n",
    "         - `correct_answer`: The specific word that goes in the blank.\n",
    "         - `distractors`: List of 3 incorrect words that fit grammatically but not semantically.\n",
    "\n",
    "    **7. 'Listening' (Comprehension)**\n",
    "       - **Usage:** Audio testing.\n",
    "       - **Data:** Fill `options` list.\n",
    "       - **Content:** The `question_en` should be \"Listen and select the correct answer\" or \"What did you hear?\".\n",
    "       - **Note:** Leave `audio_url` empty (None) unless you have a specific placeholder URL strategy.\n",
    "\n",
    "    **8. 'Speaking' (Pronunciation)**\n",
    "       - **Usage:** User reads text aloud.\n",
    "       - **Data:** Fill `speaking` field.\n",
    "       - **Logic:** `expected_text` is the Hanzi the user must say. `time_limit` usually 10-15s.\n",
    "\n",
    "    **9. 'Translate to CN' / 'Writing'**\n",
    "       - **Usage:** Output/Production practice.\n",
    "       - **Data:** Fill `text_response` field.\n",
    "       - **Logic:** `accepted_answers` must be a list of valid string variations (e.g. [\"Hello\", \"Hi\"]).\n",
    "\n",
    "    ### FORMATTING\n",
    "    Output strict JSON matching the schema. Do not explain your code.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_msg_template = \"\"\"\n",
    "    BLUEPRINT:\n",
    "    {blueprint_json}\n",
    "    \"\"\"\n",
    "    \n",
    "    if feedback and revisions > 0:\n",
    "        user_msg_template += \"\\n\\n!!! CRITICAL FEEDBACK !!!\\nReviewer Feedback: {feedback}\\nFix issues and regenerate.\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_msg),\n",
    "        (\"user\", user_msg_template),\n",
    "        (\"user\", \"\\nOutput Final Content JSON:\\n{format_instructions}\")\n",
    "    ])\n",
    "    \n",
    "    # Prepare inputs safely\n",
    "    inputs = {\n",
    "        \"blueprint_json\": plan.model_dump_json(), # Pass JSON string as variable content\n",
    "        \"format_instructions\": parser.get_format_instructions(),\n",
    "        \"feedback\": feedback if feedback else \"\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = writer_llm.invoke(prompt.invoke(inputs))\n",
    "        return {\n",
    "            \"draft_content\": parser.parse(response.content),\n",
    "            \"revision_count\": revisions + 1\n",
    "        }\n",
    "    except Exception as e:\n",
    "        # If parsing fails, trigger a revision with the error as feedback\n",
    "        return {\"critique_feedback\": f\"JSON Parsing Error: {str(e)}\", \"revision_count\": revisions + 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5fc99c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. AGENT 3: The Reviewer (Birdbrain) ---\n",
    "def reviewer_node(state: AgentState):\n",
    "    draft = state.get('draft_content')\n",
    "    course = state['course_info']\n",
    "    \n",
    "    if not draft:\n",
    "        return {\"is_approved\": False, \"critique_feedback\": \"No content generated.\"}\n",
    "        \n",
    "    parser = PydanticOutputParser(pydantic_object=CritiqueEvaluation)\n",
    "    \n",
    "    system_msg = f\"\"\"\n",
    "    You are 'Birdbrain', a strict QA Auditor.\n",
    "    \n",
    "    CHECKLIST:\n",
    "    1. HSK Compliance: Are words appropriate for {course['hsk_level']}?\n",
    "    2. Distractor Quality: Are wrong answers plausible?\n",
    "    3. Naturalness: Is the Chinese natural?\n",
    "    4. Alignment: Does content match the Architect's Blueprint?\n",
    "    \n",
    "    Return 'approved': True ONLY if perfect.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_msg_template = \"\"\"\n",
    "    DRAFT TO REVIEW:\n",
    "    {draft_json}\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_msg),\n",
    "        (\"user\", user_msg_template),\n",
    "        (\"user\", \"{format_instructions}\")\n",
    "    ])\n",
    "    \n",
    "    inputs = {\n",
    "        \"draft_json\": draft.model_dump_json(),\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    }\n",
    "    \n",
    "    response = critic_llm.invoke(prompt.invoke(inputs))\n",
    "    eval_result = parser.parse(response.content)\n",
    "    \n",
    "    return {\n",
    "        \"is_approved\": eval_result.approved,\n",
    "        \"critique_feedback\": eval_result.feedback\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9cfba649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState):\n",
    "    if state['is_approved']:\n",
    "        return \"end\"\n",
    "    if state['revision_count'] > 3:\n",
    "        return \"end\"\n",
    "    return \"revise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1874b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"architect\", architect_node)\n",
    "workflow.add_node(\"writer\", writer_node)\n",
    "workflow.add_node(\"reviewer\", reviewer_node)\n",
    "\n",
    "# Add Edges\n",
    "workflow.set_entry_point(\"architect\")\n",
    "workflow.add_edge(\"architect\", \"writer\")\n",
    "workflow.add_edge(\"writer\", \"reviewer\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"reviewer\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"revise\": \"writer\"\n",
    "    }\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e74607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tarchitect(architect)\n",
      "\twriter(writer)\n",
      "\treviewer(reviewer)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> architect;\n",
      "\tarchitect --> writer;\n",
      "\treviewer -. &nbsp;end&nbsp; .-> __end__;\n",
      "\treviewer -. &nbsp;revise&nbsp; .-> writer;\n",
      "\twriter --> reviewer;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get the graph visualization in Mermaid format\n",
    "print(app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a67e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 1. Load Data\n",
    "    # Ensure these paths are correct relative to where you run the script\n",
    "    if not os.path.exists('../input_data/lessons.csv'):\n",
    "        print(\"Error: Input files not found. Check path '../input_data/'\")\n",
    "        return\n",
    "\n",
    "    courses_df = pd.read_csv('../input_data/courses.csv') \n",
    "    lessons_df = pd.read_csv('../input_data/lessons.csv')\n",
    "\n",
    "    # Data lists (Storage for CSV export)\n",
    "    data_sections = []\n",
    "    data_quizzes = []\n",
    "    data_flashcards = []\n",
    "    data_options = []\n",
    "    data_pairs = []\n",
    "    data_sentences = []\n",
    "    data_speaking = []\n",
    "    data_text_response = []\n",
    "    \n",
    "    section_id_counter = 1\n",
    "    quiz_id_counter = 1\n",
    "\n",
    "    print(f\"Starting 3-Agent Generation Pipeline for {len(lessons_df)} lessons...\")\n",
    "\n",
    "    for _, lesson_row in lessons_df.iterrows():\n",
    "        print(f\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
    "        print(f\"â•‘ Processing: {lesson_row['title']}\")\n",
    "        print(f\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
    "        \n",
    "        # Find parent course info\n",
    "        course_row = courses_df[courses_df['id'] == lesson_row['course_id']].iloc[0]\n",
    "\n",
    "        # 2. Initial State for the 3-Agent Workflow\n",
    "        initial_state = {\n",
    "            \"course_info\": course_row.to_dict(),\n",
    "            \"lesson_info\": lesson_row.to_dict(),\n",
    "            \n",
    "            # Agent 1 Output container\n",
    "            \"lesson_plan\": None,\n",
    "            \n",
    "            # Agent 2 Output container\n",
    "            \"draft_content\": None,\n",
    "            \n",
    "            # Agent 3 Feedback container\n",
    "            \"critique_feedback\": None,\n",
    "            \n",
    "            # Loop Controls\n",
    "            \"revision_count\": 0,\n",
    "            \"is_approved\": False\n",
    "        }\n",
    "\n",
    "        # 3. Run the Graph\n",
    "        try:\n",
    "            for event in app.stream(initial_state):\n",
    "                for node_name, state_update in event.items():\n",
    "                    # Update our local state with the new data from the node\n",
    "                    initial_state.update(state_update)\n",
    "                    \n",
    "                    # Visual Feedback\n",
    "                    if node_name == \"architect\":\n",
    "                        pprint.pprint(f\"\\n[Blueprint Created] ğŸ—ï¸  Rationale: {state_update['lesson_plan'].rationale}...\")\n",
    "                    \n",
    "                    elif node_name == \"writer\":\n",
    "                        rev = initial_state.get('revision_count', 0)\n",
    "                        pprint.pprint(f\"\\n[Draft Generated] âœï¸  Revision #{rev}\")\n",
    "                    \n",
    "                    elif node_name == \"reviewer\":\n",
    "                        approved = state_update.get('is_approved')\n",
    "                        feedback = state_update.get('critique_feedback')\n",
    "                        if approved:\n",
    "                            pprint.pprint(f\"\\n âœ…[Review Passed] Birdbrain approved the content!\")\n",
    "                        else:\n",
    "                            pprint.pprint(f\"\\n âŒ[Review Failed] Feedback: {feedback}\")\n",
    "                            pprint.pprint(\"   â†ªï¸  Looping back to Writer...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Graph Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 4. Extract Final Content\n",
    "        # We grab 'draft_content' because that is the final JSON produced by the Writer\n",
    "        content: GeneratedLessonContent = initial_state.get('draft_content')\n",
    "        \n",
    "        if not content:\n",
    "            print(f\"FAILED to generate content for {lesson_row['title']}\")\n",
    "            continue\n",
    "\n",
    "        pprint.pprint(f\"âœ… Content Approved after {initial_state['revision_count']} revisions.\")\n",
    "        \n",
    "        # 5. Flatten Data for CSV Export\n",
    "        lesson_key = lesson_row['title'] \n",
    "        \n",
    "        for sec in content.sections:\n",
    "            current_section_id = section_id_counter \n",
    "            section_id_counter += 1\n",
    "            \n",
    "            # Note: Using 'title_vi' to match your Pydantic Schema and Django Model\n",
    "            data_sections.append({\n",
    "                \"id\": current_section_id, \n",
    "                \"lesson_key\": lesson_key, \n",
    "                \"section_type\": sec.section_type, \n",
    "                \"title_en\": sec.title_en, \n",
    "                \"title_vi\": sec.title_vi, \n",
    "                \"content_md\": sec.content_md, \n",
    "                \"order\": sec.order\n",
    "            })\n",
    "\n",
    "            for quiz in sec.quizzes:\n",
    "                current_quiz_id = quiz_id_counter\n",
    "                quiz_id_counter += 1\n",
    "                \n",
    "                data_quizzes.append({\n",
    "                    \"id\": current_quiz_id, \n",
    "                    \"section_id\": current_section_id, \n",
    "                    \"quiz_type\": quiz.quiz_type, \n",
    "                    \"question_en\": quiz.question_en, \n",
    "                    \"question_vi\": quiz.question_vi, \n",
    "                    \"audio_url\": quiz.audio_url,\n",
    "                    \"image_url\": quiz.image_url, \n",
    "                    \"explanation_en\": quiz.explanation_en, \n",
    "                    \"explanation_vi\": quiz.explanation_vi, \n",
    "                    \"order\": quiz.order\n",
    "                })\n",
    "\n",
    "                # --- Handle Polymorphic Data ---\n",
    "                if quiz.flashcard:\n",
    "                    data_flashcards.append({\"quiz_id\": current_quiz_id, **quiz.flashcard.model_dump()})\n",
    "                \n",
    "                if quiz.options:\n",
    "                    for opt in quiz.options:\n",
    "                        data_options.append({\"quiz_id\": current_quiz_id, **opt.model_dump()})\n",
    "                \n",
    "                if quiz.pairs:\n",
    "                    for pair in quiz.pairs:\n",
    "                        data_pairs.append({\"quiz_id\": current_quiz_id, **pair.model_dump()})\n",
    "                \n",
    "                if quiz.sentence:\n",
    "                    data_sentences.append({\"quiz_id\": current_quiz_id, **quiz.sentence.model_dump()})\n",
    "                \n",
    "                if quiz.speaking:\n",
    "                    data_speaking.append({\"quiz_id\": current_quiz_id, **quiz.speaking.model_dump()})\n",
    "                \n",
    "                if quiz.text_response:\n",
    "                    dump = quiz.text_response.model_dump()\n",
    "                    # Convert list to string for CSV compatibility\n",
    "                    dump['accepted_answers'] = str(dump['accepted_answers'])\n",
    "                    data_text_response.append({\"quiz_id\": current_quiz_id, **dump})\n",
    "\n",
    "    # 6. Save to CSV\n",
    "    os.makedirs('output_data', exist_ok=True)\n",
    "    \n",
    "    def save_csv(data, filename):\n",
    "        if data: \n",
    "            pd.DataFrame(data).to_csv(f'output_data/{filename}', index=False)\n",
    "            print(f\"Saved {filename}\")\n",
    "        else:\n",
    "            print(f\"No data for {filename}\")\n",
    "    \n",
    "    save_csv(data_sections, 'sections.csv')\n",
    "    save_csv(data_quizzes, 'quizzes.csv')\n",
    "    save_csv(data_flashcards, 'flashcards.csv')\n",
    "    save_csv(data_options, 'options.csv')\n",
    "    save_csv(data_pairs, 'pairs.csv')\n",
    "    save_csv(data_sentences, 'sentences.csv')\n",
    "    save_csv(data_speaking, 'speaking.csv')\n",
    "    save_csv(data_text_response, 'text_response.csv')\n",
    "    \n",
    "    print(\"\\nGeneration Complete. Check 'output_data/' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cec16631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 3-Agent Generation Pipeline for 2 lessons...\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Processing: Hello - NÇ hÇo\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "('\\n'\n",
      " '[Blueprint Created] ğŸ—ï¸  Rationale: This lesson is scaffolded from '\n",
      " 'acquisition to production to ensure beginners internalize the five target '\n",
      " 'objectives (nÇ hÇo, nÇ, hÇo, wÇ’, jiÃ o) in multiple modalities. 1) Vocabulary '\n",
      " 'first builds form-meaning mappings for the five lexical items (characters, '\n",
      " 'pinyin, tones) so learners can recognize and recall them. 2) Speaking '\n",
      " '(pronunciation) immediately after vocabulary trains accurate sound and tone '\n",
      " 'production, preventing fossilized pronunciation errors early. 3) Listening '\n",
      " 'gives learners receptive practice with native-speed realizations of '\n",
      " 'greetings and introductions, reinforcing vocabulary in context. 4) Grammar '\n",
      " 'explains the basic sentence pattern (subject + å« + name) and the fixed '\n",
      " 'greeting ä½ å¥½, so learners can assemble the words into correct utterances. 5) '\n",
      " 'Reading exposes learners to the same items in character form and very short '\n",
      " 'sentences to develop character recognition and reinforce meaning. 6) '\n",
      " 'Conversation provides guided application through short role-plays (greeting '\n",
      " 'and introducing oneself), moving learners from controlled practice to '\n",
      " 'communicative use. 7) Final Test reviews all modalities (vocabulary, '\n",
      " 'pronunciation, comprehension, production) with mixed items to assess '\n",
      " 'readiness and retention. Each section links explicitly to one or more '\n",
      " 'objectives and uses complementary quiz types to consolidate learning....')\n",
      "'\\n[Draft Generated] âœï¸  Revision #1'\n",
      "('\\n'\n",
      " ' âŒ[Review Failed] Feedback: Overall this draft is well-aligned to an HSK1 '\n",
      " 'beginner lesson (vocab, listening, speaking, basic grammar). However it is '\n",
      " 'not perfect â€” please fix the following concrete issues before approval:\\n'\n",
      " '\\n'\n",
      " '1) Duplicate / invalid distractor\\n'\n",
      " '   - Vocabulary section, Single Choice (order 13) \"Which pinyin matches å«?\": '\n",
      " 'the options include \"jiÄo\" twice (order 2 and 4). Remove the duplicate and '\n",
      " 'make distractors plausible (e.g., jiÄo, jiÇo, jiÃ o, jiÄo is duplicated). '\n",
      " 'Ensure only one correct \"jiÃ o\" appears.\\n'\n",
      " '\\n'\n",
      " '2) Mismatched / unnatural fill-in sentences (Chinese sentence vs prompt)\\n'\n",
      " '   - Grammar section, Fill in the Blank (order 5) Prompt: \"Fill the blank: '\n",
      " '___å¾ˆå¥½ã€‚\" Current chinese_sentence: \"ä½ å¥½ã€‚\" and correct_answer: \"ä½ å¥½\" -> that '\n",
      " 'would create \"ä½ å¥½å¾ˆå¥½ã€‚\" which is unnatural. Fix one of these: either change '\n",
      " 'prompt to \"___ï¼Œå¾ˆé«˜å…´ã€‚è¯·é—®ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\" (if you want \"ä½ å¥½\") or change correct answer to '\n",
      " '\"ä½ \" (so the sentence becomes \"ä½ å¾ˆå¥½ã€‚\") and update chinese_sentence/pinyin '\n",
      " 'accordingly.\\n'\n",
      " '   - Grammar section, Fill in the Blank (order 10) Prompt: \"Fill the blank: '\n",
      " '___å¾ˆå¥½ï¼Œè¯·é—®ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\" chinese_sentence contains \"ä½ å¥½ï¼Œå¾ˆé«˜å…´ã€‚è¯·é—®ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ\" â€” the prompt '\n",
      " 'and the stored chinese_sentence differ. Align prompt, displayed Chinese '\n",
      " 'sentence, and correct_answer.\\n'\n",
      " '   - Final Test, Fill in the Blank (order 18) \"Final written gap: ___å¾ˆå¥½ã€‚\" '\n",
      " 'chinese_sentence: \"ä½ å¥½å¾ˆå¥½ã€‚\" â€” this is unnatural. Change to either \"ä½ å¾ˆå¥½ã€‚\" or '\n",
      " 'reword prompt if you meant something else.\\n'\n",
      " '\\n'\n",
      " '3) Many \"correct_answer\" values and example Chinese sentences leave '\n",
      " 'placeholders or incomplete expected_text\\n'\n",
      " '   - Several speaking quizzes use expected_text exactly \"æˆ‘å«ã€‚\" (e.g., '\n",
      " 'Speaking sections order 16, Final Test speaking etc.). This is a placeholder '\n",
      " 'but could be confusing for automated checking. Use a template like '\n",
      " '\"æˆ‘å«[ä½ çš„åå­—]ã€‚\" in expected_pinyin/expected_text or document that a name should '\n",
      " 'be supplied. Also ensure automated graders accept free-text names.\\n'\n",
      " '\\n'\n",
      " '4) Minor naturalness / consistency issues\\n'\n",
      " '   - Several entries use phrasing with extra commas or inconsistent '\n",
      " 'punctuation (e.g., sometimes pinyin capitalized, sometimes not). For clarity '\n",
      " 'and consistency, standardize pinyin casing (lowercase for pinyin '\n",
      " 'in-sentence; initial capital only for sentence-initial English if desired) '\n",
      " 'and punctuation (use ã€‚ or ! consistently in chinese_sentence fields).\\n'\n",
      " '   - Vocabulary Vietnamese translation for ä½  currently reads \"báº¡n / báº¡n (sá»‘ '\n",
      " 'Ã­t)\" â€” redundant; simplify to \"báº¡n\".\\n'\n",
      " '\\n'\n",
      " '5) Tone-sandhi wording clarity\\n'\n",
      " '   - Speaking section, Single Choice (order 11) option text \"nÇ hÇo (both '\n",
      " '3rd tones) -> often pronounced nÃ­ hÇo or nÃ­hÇo\" is essentially correct, but '\n",
      " 'the explanation should state clearly that the first 3rd tone commonly '\n",
      " 'becomes a 2nd tone (nÃ­ hÇo). Consider rewording to: \"nÇ hÇo (3rd+3rd) â†’ '\n",
      " 'commonly pronounced nÃ­ hÇo (2nd + 3rd).\"\\n'\n",
      " '\\n'\n",
      " '6) HSK-level check for polite expressions\\n'\n",
      " '   - The lesson includes polite phrases like å¾ˆé«˜å…´è®¤è¯†ä½  and è¯·é—®. These are '\n",
      " 'appropriate in communicative contexts, but double-check your HSK-level '\n",
      " 'mapping if strict HSK1-only vocabulary is required (è®¤è¯† / è¯·é—® may fall into '\n",
      " 'HSK2 in some mappings). If the blueprint requires strictly HSK1 lexicon, '\n",
      " 'mark those as optional/extra.\\n'\n",
      " '\\n'\n",
      " '7) Typos / variants\\n'\n",
      " '   - Final Test Translate accepted answers includes \"ä½ å«ä»€éº¼åå­—ï¼Ÿ\" (traditional '\n",
      " 'è«‹/éº¼ variant). Decide whether you target simplified (ä½ å«ä»€ä¹ˆåå­—ï¼Ÿ) or accept both; '\n",
      " 'if accepting both state it explicitly.\\n'\n",
      " '\\n'\n",
      " 'Please address the above: fix the duplicate option, correct the mismatched / '\n",
      " 'unnatural fill-in sentences, make expected speaking outputs clearer for name '\n",
      " 'insertion, standardize pinyin/capitalization, and check HSK-level alignment '\n",
      " 'for polite phrases. After these fixes I can re-audit for approval.')\n",
      "'   â†ªï¸  Looping back to Writer...'\n",
      "'\\n[Draft Generated] âœï¸  Revision #2'\n",
      "('\\n'\n",
      " ' âŒ[Review Failed] Feedback: Overall the draft is strong and on-topic (core '\n",
      " 'HSK1 items ä½ å¥½, ä½ , å¥½, æˆ‘, å« are present and taught appropriately), but it is '\n",
      " 'not perfect. Please fix the following specific issues before approving:\\n'\n",
      " '\\n'\n",
      " '1) Distractor quality / ambiguous options\\n'\n",
      " ' - Remove or reword duplicate/ambiguous options like â€œjiÃ o (different '\n",
      " 'meaning)â€ that repeat the correct form (appears in Speaking Â§ quiz 15 and '\n",
      " 'elsewhere). Distractors must be distinct surface forms, not duplicates with '\n",
      " 'parenthetical notes. \\n'\n",
      " ' - In the Final Test (Multiple Choice Q15) the option â€œå«æˆ‘ + åå­— (colloquial)â€ '\n",
      " 'is marked correct. This is colloquial and not a standard HSK1 core form for '\n",
      " 'â€œMy name is â€¦â€. Either mark it false, move it to an â€œallowed colloquialâ€ '\n",
      " 'note, or clearly label it as optional/colloquial (not HSK1 core).\\n'\n",
      " ' - Some distractors are unrealistically easy (e.g., wildly different '\n",
      " 'characters like ç±³, ä½¿); consider using confusable characters/components as '\n",
      " 'distractors for character-recognition items (e.g., ä»– / å¥¹ / ä½  / ä»¬ or '\n",
      " 'characters that share a radical) to increase plausibility.\\n'\n",
      " '\\n'\n",
      " '2) HSK-level alignment\\n'\n",
      " ' - You correctly flagged å¾ˆé«˜å…´è®¤è¯†ä½  and è¯·é—® as optional extras. Ensure they are '\n",
      " 'never treated as required HSK1 answers in graded items. Several items '\n",
      " 'already mark them optional; double-check any final-test items so HSK1 pass '\n",
      " 'criteria donâ€™t depend on these extras.\\n'\n",
      " ' - The note about å§“ being HSK2 is good. Wherever you include HSK2 items, '\n",
      " 'mark them consistently as optional/extension.\\n'\n",
      " '\\n'\n",
      " '3) Listening content / audio placeholders\\n'\n",
      " ' - Many listening items have empty audio_url placeholders. Either attach the '\n",
      " 'correct audio for each listening item or clearly label the question set as '\n",
      " 'â€œaudio placeholders â€” replace before deployment.â€ Without audio, some '\n",
      " 'MC/True-False choices (e.g., which name was said, which sentence, whether a '\n",
      " 'question was asked) cannot be validated. \\n'\n",
      " ' - Ensure each listening questionâ€™s correct choice matches the specific '\n",
      " 'audio to be recorded. Currently there are multiple different â€œcorrectâ€ '\n",
      " 'answers across listening items (ææ˜, ç‹èŠ³, etc.) which is fine if different '\n",
      " 'audio clips are provided â€” but confirm audio-to-answer mapping before '\n",
      " 'release.\\n'\n",
      " '\\n'\n",
      " '4) Naturalness and clarity of Chinese / pedagogical notes\\n'\n",
      " ' - Tone-sandhi notes are good and accurate; keep them. Small wording '\n",
      " 'improvements: use consistent punctuation (either Chinese punctuation or '\n",
      " 'ASCII, but be consistent) and consistent pinyin formatting (use spaced '\n",
      " 'lower-case with tone marks: e.g., â€œnÇ hÇoâ€).\\n'\n",
      " \" - Minor translation wording: e.g., â€œWhich initial is used in 'nÇ'?â€ \"\n",
      " \"Vietnamese translation currently says â€œNguyÃªn Ã¢m Ä‘áº§u nÃ o dÃ¹ng trong 'nÇ'?â€ â€” \"\n",
      " \"technically 'initial' = consonant onset, and in Vietnamese you might say â€œÃ‚m \"\n",
      " 'Ä‘áº§u (initial)â€; not a critical error but consider clarifying as â€œÃ¢m Ä‘áº§u '\n",
      " '(initial consonant)â€ if you want to be precise.\\n'\n",
      " '\\n'\n",
      " '5) Consistency across sections\\n'\n",
      " ' - Ensure example names used in flashcards and listening (ææ˜, ç‹æ˜, ç‹èŠ³, å¼ ä¼Ÿ) '\n",
      " 'are intentionally varied. If reuse is intended, keep it consistent to avoid '\n",
      " 'learner confusion. Example: if you expect learners to hear ææ˜ in one '\n",
      " 'listening item and ææ˜ is also used as the example in the flashcard, that is '\n",
      " 'good; if not, document why different names are used.\\n'\n",
      " '\\n'\n",
      " '6) Specific small corrections to make now (actionable)\\n'\n",
      " ' - Remove the duplicate â€œjiÃ o (different meaning)â€ options and replace them '\n",
      " 'with distinct distractors (e.g., jiÄo, jiÇo, jiao without tone mark) where '\n",
      " 'appropriate.\\n'\n",
      " ' - In Final Test Multiple Choice Q15, change the correctness flag for â€œå«æˆ‘ + '\n",
      " 'åå­— (colloquial)â€ to false OR add an explicit explanatory note that it is '\n",
      " 'colloquial and not part of HSK1 core answers.\\n'\n",
      " ' - Add audio files or a clear TODO comment for every listening item and '\n",
      " 'verify correct answers against those audio files.\\n'\n",
      " ' - Standardize pinyin appearance across the draft (lower-case + space + tone '\n",
      " 'marks) and use consistent sentence punctuation.\\n'\n",
      " '\\n'\n",
      " 'If you make those fixes (remove ambiguous duplicates, tighten distractors, '\n",
      " 'attach/verify audio, and ensure optional HSK2 items are not required), I '\n",
      " 'will re-check and can approve.')\n",
      "'   â†ªï¸  Looping back to Writer...'\n",
      "'\\n[Draft Generated] âœï¸  Revision #3'\n",
      "('\\n'\n",
      " ' âŒ[Review Failed] Feedback: Overall good scope and HSK1 focus, but several '\n",
      " 'concrete fixes are needed before approval:\\n'\n",
      " '\\n'\n",
      " '1) Pinyin formatting: inconsistent with your own note. Pinyin must be '\n",
      " 'lower-case with spaces and tone marks everywhere. Currently many personal '\n",
      " 'names (e.g., â€œLÇ MÃ­ngâ€, â€œZhÄng WÄ›iâ€, â€œWÃ¡ng FÄngâ€, etc.) use capitalized '\n",
      " 'letters. Change to lower-case (e.g., â€œlÇ mÃ­ngâ€, â€œzhÄng wÄ›iâ€, â€œwÃ¡ng fÄngâ€) '\n",
      " 'and ensure consistent spacing and tone marks for all pinyin fields.\\n'\n",
      " '\\n'\n",
      " '2) Incorrect answer keys / logical errors (must be fixed so each '\n",
      " 'single-choice has exactly one correct answer unless intentional '\n",
      " 'multi-correct format):\\n'\n",
      " '   - Reading section, quiz order 8 (question: â€œWhich character is visually '\n",
      " \"similar to 'æˆ‘' and could be a plausible distractor?â€) â€” current options \"\n",
      " 'include a duplicate (â€œæ‰¾ (duplicate distractor removed)â€) and mark â€œæˆ‘â€ as '\n",
      " 'correct. That is wrong: the question asks for a plausible distractor, not '\n",
      " 'the target itself. Remove duplicate option and correct the is_correct flag '\n",
      " '(e.g., mark a plausible confusable such as æ‰¾ as the intended distractor) or '\n",
      " 'reword the question to ask â€œWhich of these is the character æˆ‘?â€ if you '\n",
      " 'intend æˆ‘ to be correct.\\n'\n",
      " '   - Final Test, quiz order 11 (question: â€œWhich of these is NOT a correct '\n",
      " \"HSK1 core way to say 'My name is ...'?â€) â€” options are inconsistent (more \"\n",
      " 'than one option marked true/false contradictorily). Ensure exactly one '\n",
      " 'option is marked correct (the NOT-correct one should be true). If you mean '\n",
      " 'â€œå«æˆ‘ + åå­—â€ is colloquial and NOT HSK1 core, mark that option as is_correct = '\n",
      " 'true and others false.\\n'\n",
      " '   - Final Test, quiz order 18 (question: â€œFinal check: Which of these is '\n",
      " 'marked as colloquial and NOT HSK1 required?â€) â€” the colloquial item is not '\n",
      " 'marked correctly. Mark the colloquial item (å«æˆ‘ + åå­—) as the correct answer.\\n'\n",
      " '\\n'\n",
      " '3) Duplicate / placeholder distractors and messy options: remove '\n",
      " 'placeholders and duplicates (e.g., the duplicate â€œæ‰¾â€ entry in Reading Q8). '\n",
      " 'Scan all multiple-choice lists for accidental duplicates or leftover notes '\n",
      " 'like â€œduplicate distractor removedâ€.\\n'\n",
      " '\\n'\n",
      " '4) Distractor quality and plausibility: review several distractors that are '\n",
      " 'either too obvious or irrelevant. Example: in some visual-character '\n",
      " 'questions use confusable characters (similar strokes/components) as '\n",
      " 'distractors (e.g., æ‰¾, æˆ–, æ‰¾) â€” but do not repeat the same distractor. Ensure '\n",
      " 'distractors are plausible confusions at HSK1 level (ä»–, å¥¹, æ‰¾, å», æˆ‘ä»¬, ä½ ä»¬, '\n",
      " 'etc.).\\n'\n",
      " '\\n'\n",
      " '5) Marking optional/extension items clearly and consistently: you label '\n",
      " 'â€œå¾ˆé«˜å…´è®¤è¯†ä½ â€ and the surname dialogue as optional/HSK2 extension in some places '\n",
      " 'â€” keep those consistently flagged in every quiz that uses them. Also the '\n",
      " 'polite form â€œæ‚¨â€ and the structure â€œæ‚¨å§“ä»€ä¹ˆï¼Ÿâ€ belong to a higher politeness '\n",
      " 'register / HSK2 area; they are currently marked optional in one place â€” keep '\n",
      " 'that marking consistent if included.\\n'\n",
      " '\\n'\n",
      " '6) Tone-sandhi note: the extra_info text about ä½ å¥½ says â€œnÇ typically becomes '\n",
      " 'a half-thirdâ€ â€” rephrase for clarity to something like â€œtone sandhi: when '\n",
      " 'two third tones occur in sequence the first often becomes a low/rising '\n",
      " 'variant; in casual speech ä½ å¥½ may sound reduced.â€ (This is optional but '\n",
      " 'improves naturalness/clarity.)\\n'\n",
      " '\\n'\n",
      " '7) Audio placeholders: you have many AUDIO_TODO placeholders. Keep them, but '\n",
      " 'note: all AUDIO_TODO clips must be replaced with native-speaker recordings '\n",
      " 'that match the indicated string and prosody before deployment. Also ensure '\n",
      " 'audio clips match the expected tone (third vs fourth tone) used in listening '\n",
      " 'discrimination items.\\n'\n",
      " '\\n'\n",
      " '8) Consistency checks: scan for consistent use of punctuation (use standard '\n",
      " 'Chinese punctuation where intended) and consistent ordering of quizzes (many '\n",
      " \"quizzes use 'order' but check there are no gaps/duplicates). Also check \"\n",
      " 'flashcard pinyin fields vs sentence-level pinyin to ensure uniform '\n",
      " 'formatting.\\n'\n",
      " '\\n'\n",
      " 'If you make the above corrections (fix pinyin casing everywhere, correct the '\n",
      " 'mislabeled/corrupt answer keys, remove duplicate placeholders, and replace '\n",
      " 'audio TODOs), re-submit for final approval.')\n",
      "'   â†ªï¸  Looping back to Writer...'\n",
      "'\\n[Draft Generated] âœï¸  Revision #4'\n",
      "('\\n'\n",
      " ' âŒ[Review Failed] Feedback: Overall structure and pedagogy are good and '\n",
      " 'aligned to HSK1 (target words are appropriate and audio placeholders are '\n",
      " 'clearly marked). However several concrete issues must be fixed before this '\n",
      " 'can be approved:\\n'\n",
      " '\\n'\n",
      " '1) Incorrect answer keys (must be corrected)\\n'\n",
      " '   - Final Test Q11 (order 11 in Final Test): The question asks â€œWhich of '\n",
      " \"these is NOT a correct HSK1 core way to say 'My name is ...'?â€ The option \"\n",
      " 'labeled \"å«æˆ‘ + åå­— (colloquial) â€” colloquial, NOT HSK1 core\" is the '\n",
      " 'NOT-correct choice and should be marked is_correct = true. Currently it is '\n",
      " 'marked false and other options are incorrectly flagged. Please correct the '\n",
      " 'is_correct flags so the colloquial item is the correct answer.\\n'\n",
      " '   - Final Test Q18 (order 18 in Final Test): The question asks which option '\n",
      " 'is marked colloquial and NOT HSK1 required. The colloquial option (å«æˆ‘ + åå­— '\n",
      " '...) should be is_correct = true; currently it is marked false while other '\n",
      " 'items are true. Fix accordingly.\\n'\n",
      " '   - Reading section Q8 (order 8 in Reading): The prompt asks \"Which '\n",
      " 'character is visually similar to \\'æˆ‘\\' and could be a plausible distractor?\" '\n",
      " 'The options include duplicates and the correct answer should be a character '\n",
      " 'other than æˆ‘ (e.g., æ‰¾ or æˆ–). Right now the option marked true is \"æˆ‘\" itself '\n",
      " 'and there is a duplicate distractor. Remove duplicate distractor and set the '\n",
      " 'intended similar character as the correct choice (or reword question if you '\n",
      " 'meant \"Which character IS \\'æˆ‘\\'?\").\\n'\n",
      " '\\n'\n",
      " '2) Distractor quality and duplicates\\n'\n",
      " '   - Several items contain duplicate or placeholder distractors (e.g., '\n",
      " 'Reading Q8 has \"æ‰¾\" and then \"æ‰¾ (duplicate distractor removed)\"). Remove '\n",
      " 'duplicates and ensure all distractors are plausible confusers (similar '\n",
      " 'shape, pronunciation, or semantic class) rather than obviously unrelated '\n",
      " 'characters (e.g., \"çŒ«\" for pinyin-nÇ is acceptable but consider fresher '\n",
      " 'confusers like ä»– or å¦³ for visual/pronoun confusion).\\n'\n",
      " '   - Scan all single-choice/match items to ensure distractors are plausible '\n",
      " '(confusable forms, similar pronunciation or orthography) and not trivially '\n",
      " 'improbable.\\n'\n",
      " '\\n'\n",
      " '3) Pinyin formatting consistency\\n'\n",
      " '   - The brief requests pinyin be lower-case with spaces and tone marks '\n",
      " '(e.g., \"nÇ hÇo\"). But many pinyin strings for personal names are capitalized '\n",
      " '(e.g., \"LÇ MÃ­ng\", \"WÃ¡ng FÄng\"). Make pinyin consistent and lower-case (e.g., '\n",
      " '\"lÇ mÃ­ng\", \"wÃ¡ng fÄng\") throughout the content (including expected_pinyin '\n",
      " 'fields). Ensure spacing and tone marks match the stated format.\\n'\n",
      " '\\n'\n",
      " '4) Minor naturalness / clarity issues\\n'\n",
      " '   - Extra-info and notes are fine, but check a few wording choices: the '\n",
      " 'speaking expected_pinyin fields sometimes omit spaces or have inconsistent '\n",
      " 'punctuation. Standardize pinyin spacing between syllables and add tone marks '\n",
      " 'consistently.\\n'\n",
      " '   - The optional phrase å¾ˆé«˜å…´è®¤è¯†ä½  is correctly marked optional â€” keep that, '\n",
      " 'but ensure you donâ€™t present it as required in any graded item.\\n'\n",
      " '\\n'\n",
      " '5) Audio placeholders and listening checks\\n'\n",
      " '   - Audio placeholders are present and labeled TODO â€” keep these, but '\n",
      " 'before deployment replace with native recordings that exactly match the '\n",
      " 'intended strings and tones. For tone-discrimination items, ensure the audio '\n",
      " 'clips are clean and that the intended tone contrasts are audible.\\n'\n",
      " '\\n'\n",
      " '6) Cross-check items vs. intent\\n'\n",
      " '   - Run a pass that programmatically verifies every option where '\n",
      " 'is_correct=true matches the human-readable intent in the question text. A '\n",
      " 'few items show mismatches (see items called out above). Also ensure '\n",
      " 'match-pairs actually pair unique items (no left/right duplicates) and order '\n",
      " 'fields do not conflict.\\n'\n",
      " '\\n'\n",
      " 'If you fix the incorrect answer flags, remove duplicate distractors, '\n",
      " 'normalize pinyin to lower-case with tone marks and consistent spacing, and '\n",
      " 'replace audio TODOs before deployment, the draft will be approval-ready.')\n",
      "'   â†ªï¸  Looping back to Writer...'\n",
      "'âœ… Content Approved after 4 revisions.'\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘ Processing: Thank you - XiÃ¨xie\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "('\\n'\n",
      " '[Blueprint Created] ğŸ—ï¸  Rationale: This lesson is scaffolded from '\n",
      " 'acquisition to production to ensure HSK 1 learners first acquire target '\n",
      " 'forms (words and accurate pronunciation), then apply them in receptive '\n",
      " 'skills (listening and reading), and finally produce them in spoken '\n",
      " 'interaction. Sections are arranged to (1) introduce and drill the four '\n",
      " 'target polite expressions (xiÃ¨xie, bÃº kÃ¨qi, zÃ ijiÃ n, duÃ¬buqÇ), (2) secure '\n",
      " 'correct pronunciation and basic tone-sandhi understanding, (3) teach simple '\n",
      " 'usage patterns and polite-response rules, (4â€“5) provide controlled receptive '\n",
      " 'practice (listening + reading) so students can recognize the phrases in '\n",
      " 'context, (6) move into guided production via role-play dialogues, and (7) '\n",
      " 'conclude with an integrated final test that mixes recognition and '\n",
      " 'production. Each section focuses on concrete micro-skills needed for '\n",
      " 'real-life use: character + pinyin recognition, tone/pronunciation, '\n",
      " 'appropriate responses, contextual comprehension, and conversational '\n",
      " 'fluency....')\n",
      "'\\n[Draft Generated] âœï¸  Revision #1'\n",
      "('\\n'\n",
      " ' âŒ[Review Failed] Feedback: Overall structure and content are strong and '\n",
      " 'appropriate for HSK1, but there are a few concrete issues to fix before '\n",
      " 'approval:\\n'\n",
      " '\\n'\n",
      " '1) Incorrect answer key (needs correction):\\n'\n",
      " \"   - Grammar section, Q4 (â€œIf someone says 'å¯¹ä¸èµ·', what is a common reply?â€) \"\n",
      " 'currently marks ä¸å®¢æ°” as correct. ä¸å®¢æ°” is a reply to â€œè°¢è°¢â€, not to an apology. '\n",
      " 'Only æ²¡å…³ç³» (and optionally æ²¡äº‹) should be marked correct here â€” set ä¸å®¢æ°” to '\n",
      " 'false.\\n'\n",
      " '\\n'\n",
      " '2) HSK-level consistency / optional phrases beyond HSK1:\\n'\n",
      " '   - Remove or flag as â€œoptionalâ€ any phrases not strictly HSK1 (examples '\n",
      " 'found: å›å¤´è§, åˆ«å®¢æ°”). If you want to keep them, label them as extension/extra '\n",
      " 'vocabulary rather than core HSK1 targets.\\n'\n",
      " '\\n'\n",
      " '3) Naturalness / small wording fixes:\\n'\n",
      " '   - Extra info for è°¢è°¢: change â€œxiÃ¨ + (neutral)xeâ€ to clearer wording, e.g. '\n",
      " 'â€œxiÃ¨ + xie (second syllable neutral tone).â€\\n'\n",
      " '   - Clarify the tone change rule for ä¸ (bÃ¹ â†’ bÃº before a 4th tone) in the '\n",
      " 'pronunciation section so learners understand why itâ€™s written bÃº kÃ¨qi.\\n'\n",
      " '\\n'\n",
      " '4) Consistency checks (minor):\\n'\n",
      " '   - Ensure pinyin formatting is consistent across the file (spacing and '\n",
      " 'tone marks). Examples: sometimes pinyin is lowercase, sometimes initial caps '\n",
      " 'â€” choose one consistent format.\\n'\n",
      " '   - Check that all listening itemsâ€™ audio (not included here) match the '\n",
      " 'answer keys. Several listening questions assume audio; verify audio files '\n",
      " 'correspond to the labeled correct option.\\n'\n",
      " '\\n'\n",
      " '5) Distractor quality: generally plausible, but review a few MC/distractor '\n",
      " 'lists where distractors could be made slightly more plausible (e.g., when '\n",
      " 'testing replies to è°¢è°¢, include æ²¡å…³ç³»/ä¸ç”¨è°¢/ä¸å®¢æ°” as distractors â€” you already do '\n",
      " 'this, but ensure ordering/labels are correct after fixing #1).\\n'\n",
      " '\\n'\n",
      " 'After fixing the incorrect answer key and addressing the HSK-level labeling '\n",
      " 'and the small naturalness notes, the content should be approvable.')\n",
      "'   â†ªï¸  Looping back to Writer...'\n",
      "'\\n[Draft Generated] âœï¸  Revision #2'\n",
      "('\\n'\n",
      " ' âŒ[Review Failed] Feedback: Overall structure and pedagogy are good, but the '\n",
      " 'draft is NOT perfect for publication. Required fixes:\\n'\n",
      " '\\n'\n",
      " '1) Remove unidiomatic/incorrect answers: \"éå¸¸è°¢è°¢ã€‚\" is not natural Chinese and '\n",
      " 'must be removed from accepted answers (replace with only \"éå¸¸æ„Ÿè°¢ã€‚\"). Appears '\n",
      " 'multiple times (role-play & final test). \\n'\n",
      " '\\n'\n",
      " '2) Standardize pinyin formatting and tone notation across the file: use '\n",
      " 'lowercase and a consistent style (recommended: xiÃ¨xie, bÃº kÃ¨qi, zÃ ijiÃ n, '\n",
      " 'duÃ¬buqÇ). Avoid inconsistent capitalisation (e.g., \"DuÃ¬buqÇ\") and '\n",
      " 'inconsistent spacing. Indicate neutral tone consistently (e.g., xiÃ¨xie â€” '\n",
      " 'second syllable neutral) in explanatory notes.\\n'\n",
      " '\\n'\n",
      " '3) Correct or replace implausible distractors and typos: examples to fix â€” '\n",
      " '\"bÃ¹ kÄ›qi (?)\", \"bÃ¹ duÃ¬buqÇ\", \"xiÃ¨xiÃ¨ (full 4th tones)\" (misleading), \"éå¸¸è°¢è°¢\" '\n",
      " 'as distractor. Use plausible distractors that are real, common beginner '\n",
      " 'phrases (e.g., å†è§ / æ²¡å…³ç³» / è°¢è°¢ / ä¸ç”¨è°¢) rather than misspellings or impossible '\n",
      " 'tone combinations.\\n'\n",
      " '\\n'\n",
      " '4) Mark optional / supplemental vocabulary and HSK-levels: you introduce '\n",
      " 'extra replies (æ²¡å…³ç³», ä¸ç”¨è°¢, æ‹œæ‹œ, åˆ«å®¢æ°”, éå¸¸æ„Ÿè°¢, ä¿é‡). Indicate clearly which items '\n",
      " 'are the four HSK1 targets (è°¢è°¢, ä¸å®¢æ°”, å†è§, å¯¹ä¸èµ·) and mark others as '\n",
      " 'optional/higher-level so learners/teachers know they are extras.\\n'\n",
      " '\\n'\n",
      " '5) Small factual clarifications: the tone-sandhi note for ä¸ is fine but '\n",
      " 'state it precisely: ä¸ is fourth tone (bÃ¹) normally, but becomes second tone '\n",
      " '(bÃº) before another fourth-tone syllable (e.g., bÃº kÃ¨qi). For å¯¹ä¸èµ·, note that '\n",
      " 'ä¸ is often reduced/neutral (duÃ¬buqÇ). Ensure these explanations are '\n",
      " 'consistent everywhere.\\n'\n",
      " '\\n'\n",
      " '6) Naturalness checks: a few example sentences or accepted answers contain '\n",
      " 'unnatural collocations (e.g., \"éå¸¸è°¢è°¢\" â€” remove). Also check that optional '\n",
      " 'replies like \"æ‹œæ‹œ\" are labelled informal if kept.\\n'\n",
      " '\\n'\n",
      " '7) Minor consistency: unify how replies are represented in expected_text for '\n",
      " 'speaking tasks (avoid embedding slashes or multiple variants without '\n",
      " 'clarifying \"one of:\" or listing accepted alternatives explicitly).\\n'\n",
      " '\\n'\n",
      " 'Make these corrections and provide a revised draft. Once these items are '\n",
      " 'fixed, the content can be re-reviewed for final approval.')\n",
      "'   â†ªï¸  Looping back to Writer...'\n",
      "'\\n[Draft Generated] âœï¸  Revision #3'\n",
      "('\\n'\n",
      " ' âŒ[Review Failed] Feedback: Overall the content is accurate and the target '\n",
      " 'phrases are appropriate for HSK1, but it is not perfect. Please fix these '\n",
      " 'issues before approving:\\n'\n",
      " '\\n'\n",
      " '1) Pinyin style inconsistency â€” standardize to lowercase with tone marks '\n",
      " 'everywhere. Many fields use initial capitals or sentence punctuation (e.g. '\n",
      " '\"XiÃ¨xie nÇ.\", \"DuÃ¬buqÇ, wÇ’ chÃ­dÃ o le.\") or mixed capitalization in '\n",
      " 'expected_pinyin. Change them to lowercase (e.g. \"xiÃ¨xie nÇ\", \"duÃ¬buqÇ, wÇ’ '\n",
      " 'chÃ­dÃ o le\"). Also ensure consistent spacing between syllables (e.g. \"bÃº '\n",
      " 'kÃ¨qi\" not \"BÃº kÃ¨qi.\").\\n'\n",
      " '\\n'\n",
      " '2) Vietnamese translations inconsistent / awkward â€” replace or unify '\n",
      " 'phrasing. Example: several items translate ä¸ç”¨è°¢ as \"khá»i khÃ¡ch\" which is '\n",
      " 'unnatural; prefer \"khÃ´ng cáº§n khÃ¡ch\" or \"khÃ´ng cáº§n cáº£m Æ¡n\". For ä¸å®¢æ°” use '\n",
      " '\"khÃ´ng cáº§n khÃ¡ch sÃ¡o / khÃ´ng cÃ³ gÃ¬\". Review all VN strings for consistent, '\n",
      " 'natural translations.\\n'\n",
      " '\\n'\n",
      " '3) æ²¡å…³ç³» usage labeling â€” clarify: æ²¡å…³ç³» is correctly listed as optional, but '\n",
      " 'some multiple-choice items treat æ²¡å…³ç³» as a correct direct equivalent of '\n",
      " '\"you\\'re welcome.\" That can mislead learners (æ²¡å…³ç³» is primarily a reply to '\n",
      " 'apologies; it can occasionally be used after thanks but is not the standard '\n",
      " '\"you\\'re welcome\"). Revise questions where æ²¡å…³ç³» is marked as a correct answer '\n",
      " 'to \"you\\'re welcome\" (or add instructor note explaining nuance).\\n'\n",
      " '\\n'\n",
      " '4) Minor naturalness / presentation fixes:\\n'\n",
      " '   - Make neutral-syllable notes consistent (e.g. xiÃ¨xie: note second '\n",
      " 'syllable neutral) and apply same pinyin convention in all explanatory '\n",
      " 'fields.\\n'\n",
      " '   - Ensure the same accepted pinyin forms are used everywhere (e.g. use '\n",
      " '\"duÃ¬buqÇ\" consistently, not sometimes \"duÃ¬buqÇ\" and sometimes other '\n",
      " 'capitalized variants).\\n'\n",
      " '\\n'\n",
      " '5) Distractor review: overall distractors are plausible, but check any items '\n",
      " 'where optional phrases are both labeled optional earlier and used as '\n",
      " 'core-correct choices later â€” ensure this is intentional and add an on-screen '\n",
      " 'note when using optional replies as correct answers.\\n'\n",
      " '\\n'\n",
      " 'Make these corrections and provide an updated draft; I will re-check and can '\n",
      " 'approve once all items above are addressed.')\n",
      "'   â†ªï¸  Looping back to Writer...'\n",
      "'\\n[Draft Generated] âœï¸  Revision #4'\n",
      "('\\n'\n",
      " ' âŒ[Review Failed] Feedback: Mostly good â€” vocabulary, natural sentences, and '\n",
      " 'distractors are appropriate. Required fixes before approval:\\n'\n",
      " '\\n'\n",
      " '1) Pinyin tone error: missing tone mark on å…³ç³» in a couple of pinyin lines. '\n",
      " 'Example lines that must be corrected: \"A: duÃ¬buqÇ. B: mÃ©i guÄnxi.\" â†’ should '\n",
      " 'be \"A: duÃ¬buqÇ. B: mÃ©i guÄnxÃ¬.\" (apply the fourth-tone mark to xÃ¬). Fix all '\n",
      " 'occurrences.\\n'\n",
      " '\\n'\n",
      " '2) Pinyin/spacing consistency: decide on a single convention for spacing '\n",
      " '(word-level spacing is recommended). For example, use \"xiÃ¨xie nÇ\", \"bÃº '\n",
      " 'kÃ¨qi\", \"zÃ ijiÃ n\", \"duÃ¬buqÇ\" consistently across quizzes and explanations.\\n'\n",
      " '\\n'\n",
      " '3) Neutral-tone representation: keep neutral-tone syllables consistently '\n",
      " \"unmarked (e.g., second syllable of xiÃ¨xie, the 'bu' in duÃ¬buqÇ). Some \"\n",
      " 'entries already do this â€” make them uniform everywhere.\\n'\n",
      " '\\n'\n",
      " 'Optional suggestion: if you intend to strictly limit material to HSK1, '\n",
      " 'double-check that any supportive words used in dialogues (e.g., è€å¸ˆ / å­¦ç”Ÿ / '\n",
      " 'æ²¡å…³ç³») are allowed by your target HSK level or label them as an extension. '\n",
      " 'Once the pinyin tone and consistency issues are fixed, the draft will meet '\n",
      " 'the checklist.')\n",
      "'   â†ªï¸  Looping back to Writer...'\n",
      "'âœ… Content Approved after 4 revisions.'\n",
      "Saved sections.csv\n",
      "Saved quizzes.csv\n",
      "Saved flashcards.csv\n",
      "Saved options.csv\n",
      "Saved pairs.csv\n",
      "Saved sentences.csv\n",
      "Saved speaking.csv\n",
      "Saved text_response.csv\n",
      "\n",
      "Generation Complete. Check 'output_data/' folder.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c59a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5071b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
