{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "468c77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a91c8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlashCardData(BaseModel):\n",
    "    word_hanzi: str\n",
    "    pinyin: str\n",
    "    definition_en: str\n",
    "    definition_vn: str\n",
    "    example_sentence: str\n",
    "    example_pinyin: str\n",
    "    example_meaning_en: str\n",
    "    example_meaning_vn: str\n",
    "    extra_info_md: Optional[str] = None\n",
    "\n",
    "class QuizOptionData(BaseModel):\n",
    "    text: str\n",
    "    is_correct: bool\n",
    "    order: int\n",
    "\n",
    "class MatchPairData(BaseModel):\n",
    "    left_text: str\n",
    "    right_text: str\n",
    "    order: int\n",
    "\n",
    "class SentenceQuizData(BaseModel):\n",
    "    chinese_sentence: str\n",
    "    pinyin_sentence: str\n",
    "    correct_answer: Optional[str] = Field(None, description=\"The word to fill in the blank\")\n",
    "    distractors: List[str] = Field(default_factory=list, description=\"Wrong options for the blank\")\n",
    "\n",
    "# --- Core Models ---\n",
    "\n",
    "class GeneratedQuiz(BaseModel):\n",
    "    quiz_type: Literal['flashcard', 'single_choice', 'matching', 'sentence', 'text_response', 'speaking']\n",
    "    question_en: str\n",
    "    question_vn: str\n",
    "    explanation_en: Optional[str] = None\n",
    "    explanation_vn: Optional[str] = None\n",
    "    order: int\n",
    "    \n",
    "    # Polymorphic fields: Only ONE of these should be filled based on quiz_type\n",
    "    flashcard: Optional[FlashCardData] = None\n",
    "    options: Optional[List[QuizOptionData]] = None\n",
    "    pairs: Optional[List[MatchPairData]] = None\n",
    "    sentence: Optional[SentenceQuizData] = None\n",
    "\n",
    "class GeneratedSection(BaseModel):\n",
    "    section_type: Literal['vocabulary', 'grammar', 'reading', 'practice', 'listening']\n",
    "    title_en: str\n",
    "    title_vn: str\n",
    "    content_md: Optional[str] = Field(None, description=\"Markdown theory for grammar/reading\")\n",
    "    order: int\n",
    "    quizzes: List[GeneratedQuiz] = Field(..., description=\"List of quizzes in this section\")\n",
    "\n",
    "class GeneratedLessonContent(BaseModel):\n",
    "    \"\"\"Output for a single Lesson\"\"\"\n",
    "    sections: List[GeneratedSection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f195457",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7, api_key=\"\") # GPT-4o is recommended for complex JSON\n",
    "\n",
    "# 2. Define State\n",
    "class GeneratorState(TypedDict):\n",
    "    course_info: dict\n",
    "    lesson_info: dict\n",
    "    generated_content: Any\n",
    "    errors: list\n",
    "\n",
    "# 3. Define the Generation Node\n",
    "def generate_lesson_content(state: GeneratorState):\n",
    "    course = state['course_info']\n",
    "    lesson = state['lesson_info']\n",
    "    \n",
    "    parser = PydanticOutputParser(pydantic_object=GeneratedLessonContent)\n",
    "\n",
    "    system_msg = \"\"\"\n",
    "    You are an expert Chinese HSK Curriculum Developer.\n",
    "    Your goal is to generate concrete lesson content (Sections -> Quizzes) based on the provided metadata.\n",
    "    \n",
    "    GUIDELINES:\n",
    "    - Language Level: {hsk_level}\n",
    "    - Support Languages: English & Vietnamese\n",
    "    - Structure: Create distinct sections (Vocabulary, Grammar, Practice).\n",
    "    - Vocabulary: Must use 'flashcard' quiz type.\n",
    "    - Grammar: Must provide markdown explanations (`content_md`) and then 'single_choice' or 'sentence' quizzes.\n",
    "    - JSON: You must strictly follow the output schema.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_msg = \"\"\"\n",
    "    GENERATE CONTENT FOR:\n",
    "    Course: {course_name}\n",
    "    Lesson Title: {lesson_title}\n",
    "    Objectives: {objectives}\n",
    "    Description: {description}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_msg),\n",
    "        (\"user\", user_msg),\n",
    "        (\"user\", \"Format Instructions: {format_instructions}\")\n",
    "    ])\n",
    "\n",
    "    formatted_prompt = prompt.invoke({\n",
    "        \"hsk_level\": course.get('hsk_level', 'HSK1'),\n",
    "        \"course_name\": course.get('name'),\n",
    "        \"lesson_title\": lesson.get('title'),\n",
    "        \"objectives\": lesson.get('learning_objectives'),\n",
    "        \"description\": lesson.get('description_en'),\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    })\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(formatted_prompt)\n",
    "        parsed_data = parser.parse(response.content)\n",
    "        return {\"generated_content\": parsed_data}\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating {lesson.get('title')}: {e}\")\n",
    "        return {\"errors\": [str(e)]}\n",
    "\n",
    "# 4. Build Graph\n",
    "workflow = StateGraph(GeneratorState)\n",
    "workflow.add_node(\"generator\", generate_lesson_content)\n",
    "workflow.set_entry_point(\"generator\")\n",
    "workflow.add_edge(\"generator\", END)\n",
    "app = workflow.compile()\n",
    "\n",
    "# 5. Main Execution Logic\n",
    "def main():\n",
    "    # Load inputs\n",
    "    courses_df = pd.read_csv('../courses_data/courses.csv')\n",
    "    lessons_df = pd.read_csv('../courses_data/lessons.csv')\n",
    "\n",
    "    # Data holders for CSV export\n",
    "    data_sections = []\n",
    "    data_quizzes = []\n",
    "    data_flashcards = []\n",
    "    data_options = []\n",
    "    data_pairs = []\n",
    "    data_sentences = []\n",
    "\n",
    "    for _, lesson_row in lessons_df.iterrows():\n",
    "        print(f\"Generating content for: {lesson_row['title']}...\")\n",
    "        \n",
    "        # Get parent course data\n",
    "        course_row = courses_df[courses_df['name'] == lesson_row['course']].iloc[0]\n",
    "\n",
    "        # Run Graph\n",
    "        inputs = {\n",
    "            \"course_info\": course_row.to_dict(),\n",
    "            \"lesson_info\": lesson_row.to_dict(),\n",
    "            \"generated_content\": None,\n",
    "            \"errors\": []\n",
    "        }\n",
    "        result = app.invoke(inputs)\n",
    "\n",
    "        if result['errors']:\n",
    "            continue\n",
    "        \n",
    "        content: GeneratedLessonContent = result['generated_content']\n",
    "        \n",
    "        # Flatten Data for CSV\n",
    "        # We use the Lesson Title to link sections back to the lesson in the DB import stage\n",
    "        lesson_key = lesson_row['title'] \n",
    "\n",
    "        for sec in content.sections:\n",
    "            sec_id = str(uuid.uuid4()) # Temporary ID for linking\n",
    "            \n",
    "            data_sections.append({\n",
    "                \"id\": sec_id,\n",
    "                \"lesson_key\": lesson_key, # Link to Lesson\n",
    "                \"section_type\": sec.section_type,\n",
    "                \"title_en\": sec.title_en,\n",
    "                \"title_vn\": sec.title_vn,\n",
    "                \"content_md\": sec.content_md,\n",
    "                \"order\": sec.order\n",
    "            })\n",
    "\n",
    "            for quiz in sec.quizzes:\n",
    "                quiz_id = str(uuid.uuid4())\n",
    "                \n",
    "                data_quizzes.append({\n",
    "                    \"id\": quiz_id,\n",
    "                    \"section_id\": sec_id, # Link to Section\n",
    "                    \"quiz_type\": quiz.quiz_type,\n",
    "                    \"question_en\": quiz.question_en,\n",
    "                    \"question_vn\": quiz.question_vn,\n",
    "                    \"explanation_en\": quiz.explanation_en,\n",
    "                    \"explanation_vn\": quiz.explanation_vn,\n",
    "                    \"order\": quiz.order\n",
    "                })\n",
    "\n",
    "                # Process specific types\n",
    "                if quiz.flashcard:\n",
    "                    data_flashcards.append({\n",
    "                        \"quiz_id\": quiz_id,\n",
    "                        **quiz.flashcard.model_dump()\n",
    "                    })\n",
    "                elif quiz.options:\n",
    "                    for opt in quiz.options:\n",
    "                        data_options.append({\n",
    "                            \"quiz_id\": quiz_id,\n",
    "                            **opt.model_dump()\n",
    "                        })\n",
    "                elif quiz.pairs:\n",
    "                    for pair in quiz.pairs:\n",
    "                        data_pairs.append({\n",
    "                            \"quiz_id\": quiz_id,\n",
    "                            **pair.model_dump()\n",
    "                        })\n",
    "                elif quiz.sentence:\n",
    "                    data_sentences.append({\n",
    "                        \"quiz_id\": quiz_id,\n",
    "                        **quiz.sentence.model_dump()\n",
    "                    })\n",
    "\n",
    "    # Export to CSV\n",
    "    os.makedirs('output_data', exist_ok=True)\n",
    "    pd.DataFrame(data_sections).to_csv('output_data/sections.csv', index=False)\n",
    "    pd.DataFrame(data_quizzes).to_csv('output_data/quizzes.csv', index=False)\n",
    "    pd.DataFrame(data_flashcards).to_csv('output_data/flashcards.csv', index=False)\n",
    "    pd.DataFrame(data_options).to_csv('output_data/options.csv', index=False)\n",
    "    pd.DataFrame(data_pairs).to_csv('output_data/pairs.csv', index=False)\n",
    "    pd.DataFrame(data_sentences).to_csv('output_data/sentences.csv', index=False)\n",
    "    \n",
    "    print(\"All CSVs generated successfully in output_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cec16631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating content for: Hello - Ni Hao...\n",
      "Generating content for: Thank you - Xie Xie...\n",
      "All CSVs generated successfully in output_data/\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc5071b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
